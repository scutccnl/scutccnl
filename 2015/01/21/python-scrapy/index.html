<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>网络爬虫框架scrapy介绍及应用——抓取新浪新闻的标题内容评论         | ENJOYHOT</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="一、综述  开始这篇博文之前，调研了相关的爬虫方法，简单罗列冰山一角。
  综述：
http://www.crifan.com/summary_about_flow_process_of_fetch_webpage_simulate_login_website_and_some_notice/">
<meta property="og:type" content="article">
<meta property="og:title" content="网络爬虫框架scrapy介绍及应用——抓取新浪新闻的标题内容评论        ">
<meta property="og:url" content="https://scutccnl.github.io/2015/01/21/python-scrapy/index.html">
<meta property="og:site_name" content="ENJOYHOT">
<meta property="og:description" content="一、综述  开始这篇博文之前，调研了相关的爬虫方法，简单罗列冰山一角。
  综述：
http://www.crifan.com/summary_about_flow_process_of_fetch_webpage_simulate_login_website_and_some_notice/">
<meta property="og:image" content="http://img.blog.csdn.net/20150121152425667?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20150121163439093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20150121163529857?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20150121163516500?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://img.blog.csdn.net/20150121171359378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:updated_time" content="2016-07-16T06:35:11.718Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="网络爬虫框架scrapy介绍及应用——抓取新浪新闻的标题内容评论        ">
<meta name="twitter:description" content="一、综述  开始这篇博文之前，调研了相关的爬虫方法，简单罗列冰山一角。
  综述：
http://www.crifan.com/summary_about_flow_process_of_fetch_webpage_simulate_login_website_and_some_notice/">
<meta name="twitter:image" content="http://img.blog.csdn.net/20150121152425667?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
    

    

    

    <link rel="stylesheet" href="/vendor/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/vendor/open-sans/styles.css">
    <link rel="stylesheet" href="/vendor/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/vendor/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/vendor/fancybox/jquery.fancybox.css">
    
    
    
    

</head>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">ENJOYHOT</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories">Categories</a>
                
                    <a class="main-nav-link" href="/tags">Tags</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/avatar.png" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tags</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/avatar.png" />
            <h2 id="name">SCUTCCNL</h2>
            <h3 id="title">Web Developer &amp; Designer</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Guangzhou, China</span>
            <a id="follow" target="_blank" href="https://github.com/scutccnl/">FOLLOW</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                37
                <span>posts</span>
            </div>
            <div class="article-info-block">
                28
                <span>tags</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/scutccnl" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="twitter" class=tooltip>
                            <i class="fa fa-twitter"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class=tooltip>
                            <i class="fa fa-facebook"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="dribbble" class=tooltip>
                            <i class="fa fa-dribbble"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="rss" class=tooltip>
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-python-scrapy" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            网络爬虫框架scrapy介绍及应用——抓取新浪新闻的标题内容评论        
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2015/01/21/python-scrapy/">
            <time datetime="2015-01-21T07:12:00.000Z" itemprop="datePublished">2015-01-21</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/python/">python</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/scrapy/">scrapy</a>, <a class="tag-link" href="/tags/spider/">spider</a>
    </div>

                    </div>
                
            </header>
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h1 id="一、综述"><a href="#一、综述" class="headerlink" title="一、综述"></a>一、综述</h1><p>  开始这篇博文之前，调研了相关的爬虫方法，简单罗列冰山一角。</p>
<p>  综述：</p>
<p><a href="http://www.crifan.com/summary_about_flow_process_of_fetch_webpage_simulate_login_website_and_some_notice/" target="_blank" rel="external">http://www.crifan.com/summary_about_flow_process_of_fetch_webpage_simulate_login_website_and_some_notice/</a></p>
 <a id="more"></a>
<p>  手动编写爬虫，httpclient是常用工具。常见的请求方式有httpget和httppost</p>
<p><a href="http://blog.csdn.net/mr_tank_/article/details/17454315" target="_blank" rel="external">http://blog.csdn.net/mr_tank_/article/details/17454315</a></p>
<p><a href="http://blog.csdn.net/chszs/article/details/16854747" target="_blank" rel="external">http://blog.csdn.net/chszs/article/details/16854747</a></p>
<p><a href="http://www.yeetrack.com/?p=779" target="_blank" rel="external">http://www.yeetrack.com/?p=779</a></p>
<p>  这个教程很全面。供参考和备查</p>
<p>  htmlunit</p>
<p>  httpclient 对js 的支持比较差，有时候需要使用htmlunit 或者selenium。</p>
<p><a href="http://www.360doc.com/content/13/1229/14/14875906_340995211.shtml" target="_blank" rel="external">http://www.360doc.com/content/13/1229/14/14875906_340995211.shtml</a></p>
<p><a href="http://blog.csdn.net/strawbingo/article/details/5768421" target="_blank" rel="external">http://blog.csdn.net/strawbingo/article/details/5768421</a></p>
<p><a href="http://www.cnblogs.com/microsoftmvp/p/3716750.html" target="_blank" rel="external">http://www.cnblogs.com/microsoftmvp/p/3716750.html</a></p>
<p> 抽取相关<br>当爬取了html 后，需要去除噪声广告，抽取有用的信息。jsoup 和tika 是非常强大的工具</p>
<p><a href="http://jsoup.org/cookbook/" target="_blank" rel="external">http://jsoup.org/cookbook/</a></p>
<p><a href="http://summerbell.iteye.com/blog/565922" target="_blank" rel="external">http://summerbell.iteye.com/blog/565922</a></p>
<p>  github开源爬虫库</p>
<p><a href="https://github.com/CrawlScript/WebCollector" target="_blank" rel="external">https://github.com/CrawlScript/WebCollector</a></p>
<p><a href="https://github.com/zhuoran/crawler4j" target="_blank" rel="external">https://github.com/zhuoran/crawler4j</a></p>
<p>  开源爬虫框架nutch</p>
<p><a href="http://www.cnblogs.com/xuekyo/archive/2013/04/18/3028559.html" target="_blank" rel="external">http://www.cnblogs.com/xuekyo/archive/2013/04/18/3028559.html</a></p>
<p><a href="http://ahei.info/nutch-tutorial.htm" target="_blank" rel="external">http://ahei.info/nutch-tutorial.htm</a></p>
<p><a href="http://lc87624.iteye.com/blog/1625677" target="_blank" rel="external">http://lc87624.iteye.com/blog/1625677</a></p>
<p>  由于要学习python语言，就关注了python爬虫的方法，scrapy框架是个成熟的开源爬虫框架，因此选择其作为学习内容。<br>Scrapy是一个基于Twisted，纯Python实现的爬虫框架，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容、图片、视频等，非常方便。</p>
<h1 id="二、scrapy框架"><a href="#二、scrapy框架" class="headerlink" title="二、scrapy框架"></a>二、scrapy框架</h1><h2 id="1、整体架构如下："><a href="#1、整体架构如下：" class="headerlink" title="1、整体架构如下："></a>1、整体架构如下：</h2><p>   <img src="http://img.blog.csdn.net/20150121152425667?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image_mark"></p>
<p> 绿线是数据流向，首先从初始URL 开始，Scheduler 会将其交给 Downloader 进行下载，下载之后会交给 Spider 进行分析，Spider分析出来的结果有两种：一种是需要进一步抓取的链接，</p>
<p>例如之前分析的“下一页”的链接，这些东西会被传回 Scheduler ；另一种是需要保存的数据，它们则被送到Item Pipeline 那里，那是对数据进行后期处理（详细分析、过滤、存储等）的</p>
<p>地方。另外，在数据流动的通道里还可以安装各种中间件，进行必要的处理。参考<a href="http://blog.csdn.net/HanTangSongMing/article/details/24454453" target="_blank" rel="external"><br>    博客
   </a></p>
<h2 id="2、工程文件介绍"><a href="#2、工程文件介绍" class="headerlink" title="2、工程文件介绍"></a>2、工程文件介绍</h2><p>假设你已经配置好环境了，进入某个文件夹pythonproject，在命令行中输入<br>scrapy startproject mypro<br>即可在pythonporoject文件夹下找到mypro的工程文件夹，结构如下：</p>
<p>├── mypro<br>│   ├── mypro<br>│   │   ├── <strong>init</strong>.py<br>│   │   ├── items.py<br>│   │   ├── pipelines.py<br>│   │   ├── settings.py<br>│   │   └── spiders<br>│   │      └── <strong>init</strong>.py<br>│   └── scrapy.cfg</p>
<p>scrapy.cfg: 项目配置文件<br>items.py: 需要提取的数据结构定义文件<br>pipelines.py:管道定义，用来对items里面提取的数据做进一步处理，如保存等<br>settings.py: 爬虫配置文件</p>
<p>Items是将要装载抓取的数据的容器，它工作方式像python里面的字典，但它提供更多的保护，比如对未定义的字段填充以防止拼写错误。它通过创建一个scrapy.item.Item类来声明<br>，定义它的属性为scrpiy.item.Field对象，就像是一个对象关系映射(ORM)，我们通过将需要的item模型化，来控制从dmoz.org获得的站点数据。虽然这次的实现并没有用到items.py和</p>
<p>pipelines.py，但大规模的爬虫还是需要注意一下解耦。<br>举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy.item <span class="keyword">import</span> Item, Field    </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozItem</span><span class="params">(Item)</span>:</span>   </div><div class="line">    title = Field()   </div><div class="line">    link = Field()   </div><div class="line">    desc = Field()</div></pre></td></tr></table></figure>
<p> 在修改初始化代码时，首先需要在pythonproject//mypro//mypro//spiders下新建一个python文件，原则上所有的实现可以在这个文件里完成，当然耦合度就高了。在这个文件中，你需要新</p>
<p>建一个类，这个类需要添加以下属性：<br>1、该类继承于某个spider类，根据自己的需求，有很多可以选，如crawSpider，BaseSpider，Spider，XMLFeedSpider，CSVFeedSpider，SitemapSpider等等<br>2、name：爬虫的识别名，它必须是唯一的，在不同的爬虫中你必须定义不同的名字，例如下文的”yourname”<br>3、start_urls：爬虫开始爬的一个URL列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些URLS开始。其他子URL将会从这些起始URL中继承性生成。<br>4、parse()：爬虫的方法，调用时候传入从每一个URL传回的Response对象作为参数，response将会是parse方法的唯一的一个参数，这个方法负责解析返回的数据、匹配抓取的数据(解析为</p>
<p>item)并跟踪更多的URL。返回前可以巧妙地运用yield方法递归调用网址，此关键词的作用是返回某个对象后继续执行。如果不用该关键字，则直接会在函数中返回。</p>
<p>一般而言，运用scrapy的步骤是这样的：<br>1、在pythonproject//mypro//mypro//spiders下新建一个python文件<br>2、导入该导入的库文件，新建一个类满足以上要求。<br>3、根据继承的类的要求和功能，定义爬取规则。<br>4、在def parse(self, response)函数中对response对象解析，将需要的内容存入item对象并返回，在这里对数据不返回而是进行进一步处理也是可以的，耦合度高。<br>5、PipeLine用来对Spider返回的Item列表进行保存操作，可以写入到文件、或者数据库等。PipeLine只有一个需要实现的方法：process_item。<br>万事具备之后，通过命令行进入pythonproject//mypro文件夹中，敲下命令行开始爬虫<br>scrapy crawl “yourname”<br>scrapy命令罗列几个，要更多请参看<a href="http://scrapy-chs.readthedocs.org/zh_CN/0.24/topics/commands.html" target="_blank" rel="external">doc</a></p>
<ul>
<li><code>scrapy startproject xxx</code> 新建一个xxx的project</li>
<li><code>scrapy crawl xxx</code> 开始爬取，必须在project中</li>
<li><code>scrapy shell url</code> 在scrapy的shell中打开url，非常实用</li>
<li><code>scrapy runspider &lt;spider_file.py&gt;</code> 可以在没有project的情况下运行爬虫</li>
</ul>
<h1 id="三、新浪新闻爬虫"><a href="#三、新浪新闻爬虫" class="headerlink" title="三、新浪新闻爬虫"></a>三、新浪新闻爬虫</h1><p>众所周知，评论一般是隐藏起来的，或者显示部分，需要手动点击加载去获取更多评论。有两种方法可以解决这种方法，一种是利用js动态解析，工作量大，也比较难实现，二是直接定位到其查询数据库的url，直接抽取。下文就是讲第二种方法。<br>新浪页面导航为我们简单分好类了<a href="http://news.sina.com.cn/guide/" target="_blank" rel="external">http://news.sina.com.cn/guide/</a>，而且每个类别中都可以找到相应的滚动新闻（url冠以roll），因而没必要用到crawSpider这个类，这个类功能很强大，不仅可以自动去重，还可以定义更多的爬取规则。例如这个链接<a href="http://roll.finance.sina.com.cn/finance/zq1/index_1.shtml" target="_blank" rel="external">http://roll.finance.sina.com.cn/finance/zq1/index_1.shtml</a>，通过修改数字可以实现不断爬取对于新闻的url，当然没有这么“好”的url也是可以找到新闻的url。例如：<a href="http://sports.sina.com.cn/nba/" target="_blank" rel="external">http://sports.sina.com.cn/nba/</a><br>可以调用的浏览器的开发工具查找对应的js代码，查看数据库的url，之后在查看评论的时候也是这样的方法（点击刷新即可）</p>
<p><img src="http://img.blog.csdn.net/20150121163439093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image_mark"></p>
<p><img src="http://img.blog.csdn.net/20150121163529857?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image_mark"></p>
<p> 访问这个<a href="http://feed.mix.sina.com.cn/api/roll/tags?channelid=6&amp;sq=x_where:digit_cl==399872&amp;begin=1401552000&amp;tags=%E6%B9%96%E4%BA%BA%2C%E9%AA%91%E5%A3%AB%2C%E7%81%AB%E7%AE%AD%2C%E8%A9%B9%E5%A7%86%E6%96%AF%2C%E7%A7%91%E6%AF%94&amp;num=30&amp;lid=-3000&amp;versionNumber=1.2.4&amp;page=4&amp;encode=utf-8&amp;callback=feedCardJsonpCallback&amp;_=1421828921159" target="_blank" rel="external">链接</a>可以查看url</p>
<p><img src="http://img.blog.csdn.net/20150121163516500?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image_mark"></p>
<p>   因此，访问这个<a href="http://roll.finance.sina.com.cn/finance/zq1/index_1.shtml" target="_blank" rel="external">链接</a>的内容，爬取新闻url,访问新闻并爬取标题、内容、评论。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/bin/env python  </span></div><div class="line"><span class="comment">#coding=utf-8  </span></div><div class="line">  </div><div class="line">  </div><div class="line"><span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector  </div><div class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request  </div><div class="line"><span class="keyword">import</span> re,os  </div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  </div><div class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> Spider  </div><div class="line"><span class="keyword">import</span> urllib2,thread  </div><div class="line">  </div><div class="line">  </div><div class="line"><span class="comment">#处理编码问题  </span></div><div class="line"><span class="keyword">import</span> sys  </div><div class="line">reload(sys)  </div><div class="line">sys.setdefaultencoding(<span class="string">'gb18030'</span>)  </div><div class="line">  </div><div class="line">  </div><div class="line"><span class="comment">#flag的作用是保证第一次爬取的时候不进行单个新闻页面内容的爬取  </span></div><div class="line">flag=<span class="number">1</span>  </div><div class="line">projectpath=<span class="string">'F:\\Python27\\pythonproject\\fuck\\'</span>  </div><div class="line">  </div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">(*response)</span>:</span>  </div><div class="line">        sel = Selector(response[<span class="number">0</span>])   </div><div class="line">        <span class="comment">#get title           </span></div><div class="line">        title = sel.xpath(<span class="string">'//h1/text()'</span>).extract()  </div><div class="line">        <span class="comment">#get pages  </span></div><div class="line">        pages=sel.xpath(<span class="string">'//div[@id="artibody"]//p/text()'</span>).extract()  </div><div class="line">        <span class="comment">#get chanel_id &amp; comment_id  </span></div><div class="line">        s=sel.xpath(<span class="string">'//meta[@name="comment"]'</span>).extract()                  </div><div class="line">              </div><div class="line">        <span class="comment">#comment_id = channel[index+3:index+15]  </span></div><div class="line">        index2=len(response[<span class="number">0</span>].url)  </div><div class="line">        news_id=response[<span class="number">0</span>].url[index2<span class="number">-14</span>:index2<span class="number">-6</span>]  </div><div class="line">        comment_id=<span class="string">'31-1-'</span>+news_id      </div><div class="line">          </div><div class="line">  </div><div class="line">  </div><div class="line">        <span class="comment">#评论内容都在这个list中  </span></div><div class="line">        cmntlist=[]  </div><div class="line">          </div><div class="line">        page=<span class="number">1</span>  </div><div class="line">          </div><div class="line">        <span class="comment">#含有新闻url,标题,内容,评论的文件  </span></div><div class="line">        file2=<span class="keyword">None</span>     </div><div class="line">          </div><div class="line">        <span class="comment">#该变量的作用是当某新闻下存在非手机用户评论时置为False  </span></div><div class="line">        is_all_tel=<span class="keyword">True</span>  </div><div class="line">          </div><div class="line">        <span class="keyword">while</span>((page==<span class="number">1</span>) <span class="keyword">or</span> (cmntlist != [])):  </div><div class="line">              </div><div class="line">            tel_count=<span class="number">0</span> <span class="comment">#each page tel_user_count  </span></div><div class="line">            <span class="comment">#提取到的评论url  </span></div><div class="line">            url=<span class="string">"http://comment5.news.sina.com.cn/page/info?version=1&amp;format=js&amp;channel=cj&amp;newsid="</span>+str(comment_id)+<span class="string">"&amp;group=0&amp;compress=1&amp;ie=gbk&amp;oe=gbk&amp;page="</span>+str</div><div class="line"></div><div class="line">(page)+<span class="string">"&amp;page_size=100"</span>  </div><div class="line">            url_contain=urllib2.urlopen(url).read()  </div><div class="line">       </div><div class="line">                  </div><div class="line">            b=<span class="string">'=&#123;'</span>  </div><div class="line">            after = url_contain[url_contain.index(b)+len(b)<span class="number">-1</span>:]  </div><div class="line">            <span class="comment">#字符串中的None对应python中的null，不然执行eval时会出错  </span></div><div class="line">            after=after.replace(<span class="string">'null'</span>,<span class="string">'None'</span>)  </div><div class="line">            <span class="comment">#转换为字典变量text  </span></div><div class="line">            text=eval(after)  </div><div class="line">              </div><div class="line">            <span class="keyword">if</span> <span class="string">'cmntlist'</span> <span class="keyword">in</span> text[<span class="string">'result'</span>]:  </div><div class="line">                cmntlist=text[<span class="string">'result'</span>][<span class="string">'cmntlist'</span>]  </div><div class="line">            <span class="keyword">else</span>:  </div><div class="line">                cmntlist=[]                          </div><div class="line">              </div><div class="line">              </div><div class="line">            <span class="keyword">if</span> cmntlist != [] <span class="keyword">and</span> (page==<span class="number">1</span>):  </div><div class="line">                filename=str(comment_id)+<span class="string">'.txt'</span>  </div><div class="line">                  </div><div class="line">                path=projectpath+<span class="string">'stock\\'</span> +filename  </div><div class="line">                file2=open(path,<span class="string">'a+'</span>)  </div><div class="line">                news_content=str(<span class="string">''</span>)  </div><div class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> pages:                                                              </div><div class="line">                    news_content=news_content+p+<span class="string">'\n'</span>  </div><div class="line">                item=<span class="string">"&lt;url&gt;"</span>+response[<span class="number">0</span>].url+<span class="string">"&lt;/url&gt;"</span>+<span class="string">'\n\n'</span>+<span class="string">"&lt;title&gt;"</span>+str(title[<span class="number">0</span>])+<span class="string">"&lt;/title&gt;\n\n"</span>+<span class="string">"&lt;content&gt;\n"</span>+str(news_content)+<span class="string">"&lt;/content&gt;\n\n&lt;comment&gt;\n"</span>  </div><div class="line">  </div><div class="line">  </div><div class="line">                file2.write(item)  </div><div class="line">            <span class="keyword">if</span> cmntlist != []:  </div><div class="line">                content=<span class="string">''</span>  </div><div class="line">                  </div><div class="line">                <span class="keyword">for</span> status_dic <span class="keyword">in</span> cmntlist:  </div><div class="line">                      </div><div class="line">                    <span class="keyword">if</span> status_dic[<span class="string">'uid'</span>]!=<span class="string">'0'</span>:  </div><div class="line">                                                  </div><div class="line">                        is_all_tel=<span class="keyword">False</span>  </div><div class="line">                          </div><div class="line">                        <span class="comment">#这一句视编码情况而定，在这里去掉decode和encode也行  </span></div><div class="line">                        s=status_dic[<span class="string">'content'</span>].decode(<span class="string">'UTF-8'</span>).encode(<span class="string">'GBK'</span>)  </div><div class="line">                          </div><div class="line">                        <span class="comment">#见另一篇博客“三张图”  </span></div><div class="line">                        s=s.replace(<span class="string">"'"</span><span class="string">"'"</span>,<span class="string">'"'</span>) </div><div class="line">                        s=s.replace(<span class="string">"\n"</span>,<span class="string">''</span>) </div><div class="line">                        s1=<span class="string">"u'"</span>+s+<span class="string">"'"</span>  </div><div class="line">                        <span class="keyword">try</span>:                          </div><div class="line">                            ss=eval(s1)                   </div><div class="line">                        <span class="keyword">except</span>:  </div><div class="line">                            <span class="keyword">try</span>:  </div><div class="line">                                s1=<span class="string">'u"'</span>+s+<span class="string">'"'</span>  </div><div class="line">                                ss=eval(s1)  </div><div class="line">                            <span class="keyword">except</span>:                            </div><div class="line">                                <span class="keyword">return</span>  </div><div class="line">                          </div><div class="line">                          </div><div class="line">                        content=content+status_dic[<span class="string">'time'</span>]+<span class="string">'\t'</span>+status_dic[<span class="string">'uid'</span>]+<span class="string">'\t'</span>+ss+<span class="string">'\n'</span>  </div><div class="line">  </div><div class="line">  </div><div class="line">                    <span class="comment">#当属于手机用户时  </span></div><div class="line">                    <span class="keyword">else</span>:  </div><div class="line">                        tel_count=tel_count+<span class="number">1</span>     </div><div class="line">                                       </div><div class="line">                <span class="comment">#当一个page下不都是手机用户时，这里也可以用is_all_tel进行判断，一种是用开关的方式，一种是统计的方式  </span></div><div class="line">                <span class="comment">#算了不改了  </span></div><div class="line">                <span class="keyword">if</span> tel_count!=len(cmntlist):  </div><div class="line">                    file2.write(content)  </div><div class="line">                      </div><div class="line">            page=page+<span class="number">1</span>  </div><div class="line">              </div><div class="line">              </div><div class="line">        <span class="comment">#while loop end here  </span></div><div class="line">          </div><div class="line">        <span class="keyword">if</span> file2!=<span class="keyword">None</span>:     </div><div class="line">            <span class="comment">#当都是手机用户时，移除文件，否则写入"&lt;/comment&gt;"到文件尾           </span></div><div class="line">            <span class="keyword">if</span> is_all_tel:  </div><div class="line">                file2.close()  </div><div class="line">                <span class="keyword">try</span>:  </div><div class="line">                    os.remove(file2.name)  </div><div class="line">                <span class="keyword">except</span> WindowsError:  </div><div class="line">                    <span class="keyword">pass</span>  </div><div class="line">            <span class="keyword">else</span>:  </div><div class="line">                file2.write(<span class="string">"&lt;/comment&gt;"</span>)  </div><div class="line">                file2.close()  </div><div class="line">  </div><div class="line">  </div><div class="line">  </div><div class="line">  </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span><span class="params">(Spider)</span>:</span>  </div><div class="line">    name = <span class="string">"stock"</span>  </div><div class="line">    allowed_domains = [<span class="string">"sina.com.cn"</span>]  </div><div class="line">     </div><div class="line">    <span class="comment">#在本程序中，start_urls并不重要，因为并没有解析  </span></div><div class="line">    start_urls = [  </div><div class="line">        <span class="string">"http://news.sina.com.cn/"</span>  </div><div class="line">    ]  </div><div class="line">      </div><div class="line">  </div><div class="line">  </div><div class="line">    <span class="keyword">global</span> projectpath  </div><div class="line">      </div><div class="line">    <span class="keyword">if</span> os.path.exists(projectpath+<span class="string">'stock'</span>):  </div><div class="line">        <span class="keyword">pass</span>  </div><div class="line">    <span class="keyword">else</span>:  </div><div class="line">        os.mkdir(projectpath+<span class="string">'stock'</span>)  </div><div class="line">      </div><div class="line">      </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span>  </div><div class="line">          </div><div class="line">        <span class="comment">#这个scrapy.selector.Selector是个不错的处理字符串的类，python对编码很严格，它却处理得很好  </span></div><div class="line">        <span class="comment">#在做这个爬虫的时候，碰到很多奇奇怪怪的编码问题，主要是中文，试过很多既有的类，BeautifulSoup处理得也不是很好  </span></div><div class="line">        sel = Selector(response)            </div><div class="line">          </div><div class="line">        <span class="keyword">global</span> flag  </div><div class="line">                              </div><div class="line">        <span class="keyword">if</span>(flag==<span class="number">1</span>):  </div><div class="line">            flag=<span class="number">2</span>  </div><div class="line">            page=<span class="number">1</span>  </div><div class="line">            <span class="keyword">while</span> page&lt;<span class="number">260</span>:   </div><div class="line">                  </div><div class="line">                url=<span class="string">"http://roll.finance.sina.com.cn/finance/zq1/index_"</span>  </div><div class="line">                  </div><div class="line">                url=url+str(page)+<span class="string">".shtml"</span>  </div><div class="line">                  </div><div class="line">  </div><div class="line">  </div><div class="line">                <span class="comment">#伪装为浏览器  </span></div><div class="line">                user_agent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>    </div><div class="line">                headers = &#123; <span class="string">'User-Agent'</span> : user_agent &#125;                    </div><div class="line">                req = urllib2.Request(url, headers=headers)  </div><div class="line">                response = urllib2.urlopen(req)    </div><div class="line">                url_contain = response.read()   </div><div class="line">                  </div><div class="line">                <span class="comment">#利用BeautifulSoup进行文档解析    </span></div><div class="line">                soup = BeautifulSoup(url_contain)                  </div><div class="line">                params = soup.findAll(<span class="string">'div'</span>,&#123;<span class="string">'class'</span>:<span class="string">'listBlk'</span>&#125;)  </div><div class="line">                  </div><div class="line">                  </div><div class="line">                <span class="keyword">if</span> os.path.exists(projectpath+<span class="string">'stock\\'</span>+<span class="string">'link'</span>):  </div><div class="line">                     <span class="keyword">pass</span>  </div><div class="line">                <span class="keyword">else</span>:  </div><div class="line">                     os.mkdir(projectpath+<span class="string">'stock\\'</span>+<span class="string">'link'</span>)  </div><div class="line">                   </div><div class="line">                filename=<span class="string">'link.txt'</span>  </div><div class="line">                  </div><div class="line">                path=projectpath+<span class="string">'stock\\link\\'</span> + filename  </div><div class="line">  </div><div class="line">  </div><div class="line">                filelink=open(path,<span class="string">'a+'</span>)  </div><div class="line">                  </div><div class="line">                  </div><div class="line">                <span class="keyword">for</span> params_item <span class="keyword">in</span> params:          </div><div class="line">                    persons = params_item.findAll(<span class="string">'li'</span>)                      </div><div class="line">                    <span class="keyword">for</span> item <span class="keyword">in</span> persons:                      </div><div class="line">                        href=item.find(<span class="string">'a'</span>)  </div><div class="line">                        mil_link= href.get(<span class="string">'href'</span>)                                                     </div><div class="line">                        filelink.write(str(mil_link)+<span class="string">'\n'</span>)                                                   </div><div class="line">                        <span class="comment">#递归调用parse,传入新的爬取url  </span></div><div class="line">                        <span class="keyword">yield</span> Request(mil_link, callback=self.parse)                                </div><div class="line">                      </div><div class="line">                                      </div><div class="line">                page=page+<span class="number">1</span>     </div><div class="line">                  </div><div class="line">        <span class="comment">#对单个新闻页面新建线程进行爬取  </span></div><div class="line">        <span class="keyword">if</span> flag!=<span class="number">1</span>:  </div><div class="line">            <span class="keyword">if</span> (response.status != <span class="number">404</span>) <span class="keyword">and</span> (response.status != <span class="number">502</span>):  </div><div class="line">                thread.start_new_thread(loop,(response,))</div></pre></td></tr></table></figure>
<p> 爬取结果：</p>
<p><img src="http://img.blog.csdn.net/20150121171359378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ3VndWd1amlhd2Vp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image_mark"></p>
<p>在爬取的过程中要注意三点：<br>1.爬取不要过于频繁，不然可能会被封ip，可以减小爬取的速度，sleep一下，或者更改设置文件，我的在F:\Python27\python\Lib\site-packages\Scrapy-0.24.4-py2.7.egg\scrapy\settings\default_settings.py<br>2.文件夹的文件上限为21845，超过后注意再新建一个文件夹爬取<br>3.线程不能开得太多，不然也可能达到上限，可以考虑用代码现在所开线程的多少或者利用分布式系统</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://scutccnl.github.io/2015/01/21/python-scrapy/" data-id="ciqosuzng001pkuibit0rqnnl" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://scutccnl.github.io/2015/01/21/python-scrapy/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://scutccnl.github.io/2015/01/21/python-scrapy/">Comments</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2015/02/25/machinelearning-KNN/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    【machine learning】KNN算法        
                
            </div>
        </a>
    
    
        <a href="/2015/01/21/machinelearning-linear-regularization/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">【machine learning】regularization        </div>
        </a>
    
</nav>


    
</article>


    
    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>

</section>
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">recent</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2016/07/16/hello-world/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2016/07/16/hello-world/" class="title"></a></p>
                            <p class="item-date"><time datetime="2016-07-16T06:35:11.694Z" itemprop="datePublished">2016-07-16</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2016/07/08/Stacking/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a></p>
                            <p class="item-title"><a href="/2016/07/08/Stacking/" class="title">Stacking</a></p>
                            <p class="item-date"><time datetime="2016-07-08T09:04:30.000Z" itemprop="datePublished">2016-07-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2016/05/08/ensemble-stacking/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a></p>
                            <p class="item-title"><a href="/2016/05/08/ensemble-stacking/" class="title">ensemble-stacking</a></p>
                            <p class="item-date"><time datetime="2016-05-08T09:04:30.000Z" itemprop="datePublished">2016-05-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2016/03/12/MS-document-online-preview/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/python/">python</a></p>
                            <p class="item-title"><a href="/2016/03/12/MS-document-online-preview/" class="title">MS-document-online-preview</a></p>
                            <p class="item-date"><time datetime="2016-03-12T10:41:00.000Z" itemprop="datePublished">2016-03-12</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2015/12/12/git-notes/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/git/">git</a></p>
                            <p class="item-title"><a href="/2015/12/12/git-notes/" class="title">Git 协作纪要</a></p>
                            <p class="item-date"><time datetime="2015-12-12T10:41:00.000Z" itemprop="datePublished">2015-12-12</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HPC/">HPC</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Search-Engine/">Search Engine</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/android/">android</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/database/">database</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/django/">django</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">life</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/photo/">photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tea/">tea</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a><span class="category-list-count">2</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">February 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">December 2014</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">November 2014</a><span class="archive-list-count">9</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSDN/">CSDN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML-foundation/">ML foundation</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PageRank/">PageRank</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/benchmark/">benchmark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/classifier/">classifier</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cluster/">cluster</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/js-func/">js func</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/">life</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/listview/">listview</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongoengine/">mongoengine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ndk/">ndk</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/photo/">photo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pymongo/">pymongo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-foundation/">python foundation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-web/">python web</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reflect/">reflect</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/servlet/">servlet</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/">spider</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tea/">tea</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/">tomcat</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ubuntu/">ubuntu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/virtual-box/">virtual box</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/协作/">协作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/实验室/">实验室</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CSDN/" style="font-size: 13.33px;">CSDN</a> <a href="/tags/ML-foundation/" style="font-size: 20px;">ML foundation</a> <a href="/tags/PageRank/" style="font-size: 13.33px;">PageRank</a> <a href="/tags/benchmark/" style="font-size: 10px;">benchmark</a> <a href="/tags/classifier/" style="font-size: 10px;">classifier</a> <a href="/tags/cluster/" style="font-size: 10px;">cluster</a> <a href="/tags/js-func/" style="font-size: 13.33px;">js func</a> <a href="/tags/life/" style="font-size: 16.67px;">life</a> <a href="/tags/linux/" style="font-size: 13.33px;">linux</a> <a href="/tags/listview/" style="font-size: 10px;">listview</a> <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/mongoengine/" style="font-size: 10px;">mongoengine</a> <a href="/tags/ndk/" style="font-size: 13.33px;">ndk</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pymongo/" style="font-size: 10px;">pymongo</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/python-foundation/" style="font-size: 10px;">python foundation</a> <a href="/tags/python-web/" style="font-size: 10px;">python web</a> <a href="/tags/reflect/" style="font-size: 10px;">reflect</a> <a href="/tags/scrapy/" style="font-size: 10px;">scrapy</a> <a href="/tags/servlet/" style="font-size: 13.33px;">servlet</a> <a href="/tags/spider/" style="font-size: 16.67px;">spider</a> <a href="/tags/tea/" style="font-size: 10px;">tea</a> <a href="/tags/tomcat/" style="font-size: 13.33px;">tomcat</a> <a href="/tags/ubuntu/" style="font-size: 10px;">ubuntu</a> <a href="/tags/virtual-box/" style="font-size: 10px;">virtual box</a> <a href="/tags/协作/" style="font-size: 10px;">协作</a> <a href="/tags/实验室/" style="font-size: 10px;">实验室</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2016 enjoyhot<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    <script>
    var disqus_config = function () {
        
            this.page.url = 'https://scutccnl.github.io/2015/01/21/python-scrapy/';
        
        this.page.identifier = 'python-scrapy';
    };
    (function() { 
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'hexo-theme-icarus' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>



    
        <script src="/vendor/fancybox/jquery.fancybox.pack.js"></script>
    


<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>